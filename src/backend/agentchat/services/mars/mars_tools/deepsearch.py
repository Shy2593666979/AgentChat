import time
from typing import Optional
from langchain.tools import tool
from langgraph.config import get_stream_writer
from langchain_core.messages import HumanMessage
from agentchat.services.deepsearch.stream_graph import StreamingGraph

@tool(parse_docstring=True)
async def deep_search(user_input: str, user_id: Optional[str] = None):
    """
     æ‰§è¡Œæ·±åº¦æœç´¢ï¼Œå¤„ç†ç”¨æˆ·æŸ¥è¯¢å¹¶è¿”å›æ·±åº¦æœç´¢åçš„ç»“æœ

    Args:
        user_input: ç”¨æˆ·çš„æœç´¢çš„ä¿¡æ¯
        user_id: å½“å‰ç”¨æˆ·IDï¼Œé»˜è®¤ä¸ºNone

    Returns:
        è¿”å›æ·±åº¦æœç´¢åçš„ä¿¡æ¯
    """
    writer = get_stream_writer()
    messages = [HumanMessage(content=user_input)]

    stream_graph = StreamingGraph()

    async for chunk in stream_graph.run_with_streaming(messages):
        chunk_type = chunk.get('type', 'unknown')
        node = chunk.get('node', 'unknown')
        content = chunk.get('content', '')

        event_data = {
            "type": "response_chunk",
            "time": time.time(),
            "data": ""
        }
        if chunk_type == "streaming":
            event_data["data"] = content
        elif chunk_type in ["start", "complete", "error"]:
            emoji = {"start": "ğŸš€", "complete": "âœ…", "error": "âŒ"}[chunk_type]
            event_data["data"] = f"\n #### {emoji} {content}"
        elif chunk_type == "final_result":
            event_data["data"] = f""
        if event_data.get("data"):
            writer(event_data)


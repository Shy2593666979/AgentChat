# AgentChat v2.2.0 è¿ç§»æŒ‡å—

> **ä» LangChain 0.x å‡çº§åˆ° LangChain 1.0+ çš„å®Œæ•´è¿ç§»æŒ‡å—**

## ğŸ“‹ æ¦‚è¿°

AgentChat v2.2.0 æ˜¯ä¸€ä¸ªé‡å¤§ç‰ˆæœ¬æ›´æ–°ï¼Œä¸»è¦å˜æ›´æ˜¯å°† LangChain ä» 0.x ç‰ˆæœ¬å‡çº§åˆ° 1.0+ ç‰ˆæœ¬ã€‚LangChain 1.0 å¼•å…¥äº†**é©å‘½æ€§çš„æ¶æ„å˜æ›´**ï¼š

- ğŸ”„ **å…¨æ–°çš„ Agent ç³»ç»Ÿ**: ä» `initialize_agent` å®Œå…¨è¿ç§»åˆ° `create_agent`
- ğŸ› ï¸ **å·¥å…·ç³»ç»Ÿé‡æ„**: ä½¿ç”¨ `@tool` è£…é¥°å™¨å’Œæ–°çš„å·¥å…·å®šä¹‰æ–¹å¼
- ğŸ¯ **ä¸­é—´ä»¶æ¶æ„**: å…¨æ–°çš„ä¸­é—´ä»¶ç³»ç»Ÿæ›¿ä»£æ—§çš„å›è°ƒæœºåˆ¶
- ğŸ“Š **çŠ¶æ€ç®¡ç†**: åŸºäº TypedDict çš„çŠ¶æ€ç³»ç»Ÿ
- ğŸŒŠ **æµå¼å¤„ç†**: åŸç”Ÿæ”¯æŒæµå¼å“åº”å’Œå®æ—¶äº¤äº’

## ğŸš¨ é‡è¦æé†’

- **å®Œå…¨é‡å†™**: è¿™ä¸æ˜¯ç®€å•çš„ç‰ˆæœ¬å‡çº§ï¼Œè€Œæ˜¯æ¶æ„çš„å®Œå…¨é‡å†™
- **å¤‡ä»½æ•°æ®**: å‡çº§å‰è¯·åŠ¡å¿…å¤‡ä»½æ‚¨çš„æ•°æ®åº“å’Œé…ç½®æ–‡ä»¶
- **æµ‹è¯•ç¯å¢ƒ**: å¼ºçƒˆå»ºè®®å…ˆåœ¨æµ‹è¯•ç¯å¢ƒä¸­è¿›è¡Œå®Œæ•´éªŒè¯
- **ä¾èµ–å†²çª**: LangChain 1.0 å¯¹ä¾èµ–åŒ…æœ‰ä¸¥æ ¼è¦æ±‚
- **å­¦ä¹ æˆæœ¬**: æ–°æ¶æ„éœ€è¦é‡æ–°å­¦ä¹  Agent å¼€å‘æ¨¡å¼

---

## ğŸ“¦ ç‰ˆæœ¬å¯¹æ¯”

| ç»„ä»¶ |     v2.1.x åŠä»¥ä¸‹     |    v2.2.0+     | è¯´æ˜ |
|:---:|:------------------:|:--------------:|:---|
| **LangChain** |        0.x         |     1.0.3+     | æ ¸å¿ƒæ¡†æ¶å®Œå…¨é‡å†™ |
| **LangChain Community** |        0.x         |     0.4.1+     | ç¤¾åŒºç»„ä»¶åŒ… |
| **LangChain OpenAI** |        0.x         |     1.0.2+     | OpenAI é›†æˆåŒ… |
| **LangGraph** |         -          |     1.0.2+     | å›¾å½¢åŒ– Agent ç¼–æ’ï¼ˆæ ¸å¿ƒï¼‰ |
| **Agent æ¶æ„** | `initialize_agent` | `create_agent` | å®Œå…¨ä¸åŒçš„å®ç°æ–¹å¼ |

---

## ğŸ”„ ä¸»è¦å˜æ›´å†…å®¹

### 1. **åŒ…ç»“æ„é‡ç»„**

#### å˜æ›´å‰ (LangChain 0.x)
```python
from langchain.llms import OpenAI
from langchain.chat_models import ChatOpenAI
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.agents import initialize_agent, AgentType
from langchain.tools import Tool
from langchain.memory import ConversationBufferMemory
from langchain.schema import HumanMessage, AIMessage
from langchain.callbacks.base import BaseCallbackHandler
```

#### å˜æ›´å (LangChain 1.0+)
```python
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.tools import BaseTool, tool
from langchain_core.messages import BaseMessage, AIMessage, HumanMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.callbacks import BaseCallbackHandler
from langchain.agents import create_agent  # æ–°çš„æ ¸å¿ƒå‡½æ•°
from langchain.agents.middleware import wrap_tool_call, after_model
```

### 2. **Agent æ¶æ„é©å‘½æ€§å˜æ›´ - ä» initialize_agent åˆ° create_agent**

#### å˜æ›´å‰ (LangChain 0.x)
```python
from langchain.agents import initialize_agent, AgentType
from langchain.memory import ConversationBufferMemory

# æ—§çš„ Agent åˆå§‹åŒ–æ–¹å¼
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,
    memory=memory,
    verbose=True
)

# è¿è¡Œ Agent
result = agent.run("Hello, what can you do?")
```

#### å˜æ›´å (LangChain 1.0+ å®˜æ–¹æ¨è)
```python
from langchain.agents import create_agent
from langchain_core.messages import HumanMessage

# æ–¹å¼1: ä½¿ç”¨æ¨¡å‹æ ‡è¯†ç¬¦å­—ç¬¦ä¸² (æœ€ç®€å•)
agent = create_agent("gpt-4o", tools=tools)

# æ–¹å¼2: ä½¿ç”¨æ¨¡å‹å®ä¾‹ (æ›´å¤šæ§åˆ¶)
from langchain_openai import ChatOpenAI
model = ChatOpenAI(model="gpt-4o", temperature=0.1, max_tokens=1000)
agent = create_agent(model, tools=tools)

# æ–¹å¼3: æ·»åŠ ç³»ç»Ÿæç¤º
agent = create_agent(
    model="gpt-4o",
    tools=tools,
    system_prompt="You are a helpful assistant. Be concise and accurate."
)

# è¿è¡Œ Agent (æ–°çš„è°ƒç”¨æ–¹å¼)
result = agent.invoke({
    "messages": [{"role": "user", "content": "Hello, what can you do?"}]
})

# æµå¼è°ƒç”¨
for chunk in agent.stream({
    "messages": [{"role": "user", "content": "Search for AI news"}]
}):
    print(chunk)
```

### 3. **å·¥å…·ç³»ç»Ÿå®Œå…¨é‡æ„**

#### å˜æ›´å‰ (LangChain 0.x)
```python
from langchain.tools import Tool

def search_function(query: str) -> str:
    return f"Search results for: {query}"

# ç®€å•å·¥å…·å®šä¹‰
tool = Tool(
    name="Search",
    description="Search for information",
    func=search_function
)

# ä½¿ç”¨å·¥å…·
tools = [tool]
agent = initialize_agent(tools=tools, llm=llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION)
```

#### å˜æ›´å (LangChain 1.0+ å®˜æ–¹æ¨è)
```python
from langchain_core.tools import tool
from typing import Annotated

# æ–¹å¼1: ä½¿ç”¨ @tool è£…é¥°å™¨ (å®˜æ–¹æ¨è)
@tool
def search(query: Annotated[str, "The search query"]) -> str:
    """Search for information on the internet."""
    return f"Search results for: {query}"

@tool
def get_weather(location: Annotated[str, "The location to get weather for"]) -> str:
    """Get weather information for a location."""
    return f"Weather in {location}: Sunny, 72Â°F"

# ä½¿ç”¨å·¥å…· - æ–°çš„ create_agent æ–¹å¼
from langchain.agents import create_agent

agent = create_agent("gpt-4o", tools=[search, get_weather])

# æ–¹å¼2: ç»§æ‰¿ BaseTool (é«˜çº§ç”¨æ³•)
from langchain_core.tools import BaseTool
from pydantic import BaseModel, Field

class SearchInput(BaseModel):
    query: str = Field(description="The search query")

class SearchTool(BaseTool):
    name: str = "search"
    description: str = "Search for information"
    args_schema: type[BaseModel] = SearchInput

    def _run(self, query: str) -> str:
        return f"Search results for: {query}"

    async def _arun(self, query: str) -> str:
        return f"Async search results for: {query}"
```

### 4. **ä¸­é—´ä»¶ç³»ç»Ÿ - å…¨æ–°çš„æ‰©å±•æœºåˆ¶**

#### æ–°å¢åŠŸèƒ½ (LangChain 1.0+)
LangChain 1.0 å¼•å…¥äº†å¼ºå¤§çš„ä¸­é—´ä»¶ç³»ç»Ÿï¼Œæ›¿ä»£äº†æ—§çš„å›è°ƒæœºåˆ¶ï¼š

```python
from langchain.agents import create_agent
from langchain.agents.middleware import wrap_tool_call, after_model, wrap_model_call
from langchain_core.messages import ToolMessage

# å·¥å…·è°ƒç”¨ä¸­é—´ä»¶ - å¤„ç†å·¥å…·æ‰§è¡Œ
@wrap_tool_call
def handle_tool_errors(request, handler):
    """å¤„ç†å·¥å…·æ‰§è¡Œé”™è¯¯"""
    try:
        return handler(request)
    except Exception as e:
        return ToolMessage(
            content=f"Tool error: {str(e)}",
            tool_call_id=request.tool_call["id"]
        )

# æ¨¡å‹åå¤„ç†ä¸­é—´ä»¶
@after_model
def log_model_response(state, runtime):
    """è®°å½•æ¨¡å‹å“åº”"""
    last_message = state["messages"][-1]
    print(f"Model response: {last_message.content}")
    return None

# åŠ¨æ€æ¨¡å‹é€‰æ‹©ä¸­é—´ä»¶
@wrap_model_call
def dynamic_model_selection(request, handler):
    """åŸºäºå¯¹è¯å¤æ‚åº¦é€‰æ‹©æ¨¡å‹"""
    message_count = len(request.state["messages"])
    if message_count > 10:
        # é•¿å¯¹è¯ä½¿ç”¨é«˜çº§æ¨¡å‹
        from langchain_openai import ChatOpenAI
        advanced_model = ChatOpenAI(model="gpt-4o")
        return handler(request.override(model=advanced_model))
    return handler(request)

# åˆ›å»ºå¸¦ä¸­é—´ä»¶çš„ Agent
agent = create_agent(
    model="gpt-4o-mini",
    tools=[search, get_weather],
    middleware=[handle_tool_errors, log_model_response, dynamic_model_selection]
)
```

### 5. **ç»“æ„åŒ–è¾“å‡º - æ–°çš„å“åº”æ ¼å¼æ§åˆ¶**

#### æ–°å¢åŠŸèƒ½ (LangChain 1.0+)
```python
from pydantic import BaseModel
from langchain.agents import create_agent
from langchain.agents.structured_output import ToolStrategy, ProviderStrategy

class ContactInfo(BaseModel):
    name: str
    email: str
    phone: str

# æ–¹å¼1: ä½¿ç”¨ ToolStrategy (å…¼å®¹æ‰€æœ‰æ”¯æŒå·¥å…·è°ƒç”¨çš„æ¨¡å‹)
agent = create_agent(
    model="gpt-4o-mini",
    tools=[search_tool],
    response_format=ToolStrategy(ContactInfo)
)

# æ–¹å¼2: ä½¿ç”¨ ProviderStrategy (ä»…æ”¯æŒåŸç”Ÿç»“æ„åŒ–è¾“å‡ºçš„æ¨¡å‹)
agent = create_agent(
    model="gpt-4o",
    response_format=ProviderStrategy(ContactInfo)
)

result = agent.invoke({
    "messages": [{"role": "user", "content": "Extract contact info from: John Doe, john@example.com, (555) 123-4567"}]
})

# è®¿é—®ç»“æ„åŒ–å“åº”
contact = result["structured_response"]
# ContactInfo(name='John Doe', email='john@example.com', phone='(555) 123-4567')
```

### 6. **è‡ªå®šä¹‰çŠ¶æ€ç®¡ç† - æ‰©å±• Agent è®°å¿†**

#### å˜æ›´å‰ (LangChain 0.x)
```python
from langchain.memory import ConversationBufferMemory

# ç®€å•çš„å†…å­˜ç®¡ç†
memory = ConversationBufferMemory(return_messages=True)
```

#### å˜æ›´å (LangChain 1.0+)
```python
from langchain.agents import AgentState, create_agent
from typing import TypedDict

# è‡ªå®šä¹‰çŠ¶æ€ - å¿…é¡»ç»§æ‰¿ AgentState å¹¶ä½¿ç”¨ TypedDict
class CustomState(AgentState):
    user_preferences: dict
    conversation_context: str
    tool_usage_count: int

# æ–¹å¼1: é€šè¿‡ state_schema å‚æ•°
agent = create_agent(
    model="gpt-4o",
    tools=[search, get_weather],
    state_schema=CustomState
)

# è°ƒç”¨æ—¶ä¼ å…¥è‡ªå®šä¹‰çŠ¶æ€
result = agent.invoke({
    "messages": [{"role": "user", "content": "I prefer technical explanations"}],
    "user_preferences": {"style": "technical", "verbosity": "detailed"},
    "conversation_context": "software development discussion",
    "tool_usage_count": 0
})

# æ–¹å¼2: é€šè¿‡ä¸­é—´ä»¶å®šä¹‰çŠ¶æ€ (æ¨è)
from langchain.agents.middleware import AgentMiddleware

class CustomMiddleware(AgentMiddleware):
    state_schema = CustomState
    
    def before_model(self, state: CustomState, runtime):
        # åœ¨æ¨¡å‹è°ƒç”¨å‰å¤„ç†çŠ¶æ€
        state["tool_usage_count"] += 1
        return None

agent = create_agent(
    model="gpt-4o",
    tools=[search, get_weather],
    middleware=[CustomMiddleware()]
)
```

### 7. **æµå¼å¤„ç†å¢å¼º**

#### å˜æ›´å‰ (LangChain 0.x)
```python
# ç®€å•çš„åŒæ­¥è°ƒç”¨
result = agent.run("What's the weather like?")
print(result)
```

#### å˜æ›´å (LangChain 1.0+)
```python
# æµå¼å¤„ç† - æ˜¾ç¤ºä¸­é—´æ­¥éª¤
for chunk in agent.stream({
    "messages": [{"role": "user", "content": "Search for AI news and summarize"}]
}, stream_mode="values"):
    # æ¯ä¸ª chunk åŒ…å«è¯¥æ—¶åˆ»çš„å®Œæ•´çŠ¶æ€
    latest_message = chunk["messages"][-1]
    if latest_message.content:
        print(f"Agent: {latest_message.content}")
    elif latest_message.tool_calls:
        print(f"Calling tools: {[tc['name'] for tc in latest_message.tool_calls]}")
```

---

## ğŸ› ï¸ AgentChat ç‰¹å®šå˜æ›´

### 1. **MCP é›†æˆæ›´æ–°**

#### æ–‡ä»¶ä½ç½®
- `src/backend/agentchat/services/mcp_openai/mcp_langchain.py`

#### å˜æ›´å‰
```python
from langchain.tools import Tool
from pydantic import BaseModel, Field, create_model

def convert_base_tool(tool_name, tool_description, schema: Dict[str, Any]):
    schema_model = create_model_from_schema(tool_name, schema)
    return Tool(
        name=tool_name,
        description=tool_description,
        func=lambda **kwargs: call_mcp_tool(kwargs),
        args_schema=schema_model
    )
```

#### å˜æ›´å
```python
from langchain_core.tools import BaseTool, tool
from pydantic import BaseModel, Field, create_model
from typing import Any, Dict, Type

@tool
async def mcp_tool_wrapper(tool_name: str, **kwargs) -> str:
    """MCPå·¥å…·åŒ…è£…å™¨ï¼Œæ”¯æŒå¼‚æ­¥è°ƒç”¨"""
    return await call_mcp_tools([{
        "server_name": kwargs.get("server_name"),
        "url": kwargs.get("url"),
        "type": kwargs.get("type"),
        "tool_name": tool_name,
        "tool_args": kwargs
    }])

class MCPTool(BaseTool):
    name: str
    description: str
    server_config: Dict[str, Any]
    
    def _run(self, **kwargs) -> str:
        # åŒæ­¥å·¥å…·æ‰§è¡Œ
        return asyncio.run(self._arun(**kwargs))
    
    async def _arun(self, **kwargs) -> str:
        # å¼‚æ­¥å·¥å…·æ‰§è¡Œ
        mcp_args = [{
            "server_name": self.server_config["name"],
            "url": self.server_config["url"],
            "type": self.server_config["type"],
            "tool_name": self.name,
            "tool_args": kwargs
        }]
        return await call_mcp_tools(mcp_args)
```

### 2. **Mars Agent æ›´æ–°**

#### æ–‡ä»¶ä½ç½®
- `src/backend/agentchat/services/mars/mars_agent.py`

#### å˜æ›´å‰
```python
from langchain.agents import initialize_agent, AgentType
from langchain.memory import ConversationBufferMemory

class MarsAgent:
    def __init__(self, mars_config: MarsConfig):
        self.mars_tools = None
        self.mars_config = mars_config
        
    def setup_agent(self):
        memory = ConversationBufferMemory(return_messages=True)
        return initialize_agent(
            tools=self.mars_tools,
            llm=self.conversation_model,
            agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,
            memory=memory,
            verbose=True
        )
```

#### å˜æ›´å
```python
from langchain.agents import create_agent
from langchain.agents.middleware import wrap_tool_call, after_model
from langchain_core.messages import BaseMessage, AIMessage, ToolMessage

class MarsAgent:
    def __init__(self, mars_config: MarsConfig):
        self.mars_tools = None
        self.mars_config = mars_config
        self.mars_output_queue = None
        self.reasoning_interrupt = None

    async def init_mars_agent(self):
        self.mars_tools = await self.setup_mars_tools()
        await self.setup_language_model()
        self.middlewares = await self.setup_middlewares()
        self.react_agent = self.setup_react_agent()

    def setup_react_agent(self):
        return create_agent(
            model=self.conversation_model,
            tools=self.mars_tools,
            middleware=self.middlewares,
            system_prompt="You are a helpful Mars assistant"
        )

    async def setup_middlewares(self):
        @after_model
        async def handler_after_model(state, runtime):
            last_message = state["messages"][-1]
            if not last_message.tool_calls:
                await self.mars_output_queue.put(None)
            return None

        @wrap_tool_call
        async def handler_tool_call(request, handler):
            request.tool_call["args"].update({"user_id": self.mars_config.user_id})
            tool_result = await handler(request)
            return ToolMessage(content=tool_result, tool_call_id=request.tool_call["id"])

        return [handler_after_model, handler_tool_call]

    async def ainvoke_stream(self, messages: List[BaseMessage]):
        """æµå¼è°ƒç”¨Mars Agent"""
        self.reasoning_interrupt = asyncio.Event()
        self.mars_output_queue = asyncio.Queue()
        
        callback = UsageMetadataCallbackHandler()
        
        async for chunk in self.react_agent.astream(
            input={"messages": messages},
            config={"callbacks": [callback]},
            stream_mode=["custom"]
        ):
            await self.mars_output_queue.put(chunk)
        
        await self.mars_output_queue.put(None)
```

### 3. **RAG ç³»ç»Ÿæ›´æ–°**

#### æ–‡ä»¶ä½ç½®
- `src/backend/agentchat/services/rag/`

#### å˜æ›´å‰
```python
from langchain.vectorstores import Chroma, Milvus
from langchain.embeddings import OpenAIEmbeddings, HuggingFaceEmbeddings
from langchain.document_loaders import PyMuPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
```

#### å˜æ›´å
```python
from langchain_community.vectorstores import Chroma, Milvus
from langchain_openai import OpenAIEmbeddings
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.document_loaders import PyMuPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
```

### 4. **å·¥å…·ç³»ç»Ÿç»Ÿä¸€æ›´æ–°**

#### æ–‡ä»¶ä½ç½®
- `src/backend/agentchat/tools/`

#### å˜æ›´å‰
```python
from langchain.tools import Tool

def create_weather_tool():
    return Tool(
        name="get_weather",
        description="Get weather information",
        func=get_weather_data
    )
```

#### å˜æ›´å
```python
from langchain_core.tools import tool
from typing import Annotated

@tool
def get_weather(
    location: Annotated[str, "The location to get weather for"],
    unit: Annotated[str, "Temperature unit (celsius/fahrenheit)"] = "celsius"
) -> str:
    """Get current weather information for a specific location."""
    return get_weather_data(location, unit)

# æˆ–è€…ä½¿ç”¨ç±»å®šä¹‰
from langchain_core.tools import BaseTool
from pydantic import BaseModel, Field

class WeatherInput(BaseModel):
    location: str = Field(description="The location to get weather for")
    unit: str = Field(default="celsius", description="Temperature unit")

class WeatherTool(BaseTool):
    name: str = "get_weather"
    description: str = "Get current weather information"
    args_schema: type[BaseModel] = WeatherInput

    def _run(self, location: str, unit: str = "celsius") -> str:
        return get_weather_data(location, unit)

    async def _arun(self, location: str, unit: str = "celsius") -> str:
        return await get_weather_data_async(location, unit)
```

---

## ğŸ“‹ è¿ç§»æ­¥éª¤

### æ­¥éª¤ 1: ç¯å¢ƒå‡†å¤‡

```bash
# 1. å¤‡ä»½å½“å‰ç¯å¢ƒ
cp requirements.txt requirements.txt.backup
cp pyproject.toml pyproject.toml.backup

# 2. åˆ›å»ºæ–°çš„è™šæ‹Ÿç¯å¢ƒ
python -m venv venv_v2.2.0
source venv_v2.2.0/bin/activate  # Linux/Mac
# æˆ–
venv_v2.2.0\Scripts\activate  # Windows

# 3. å®‰è£…æ–°ç‰ˆæœ¬ä¾èµ–
pip install -r requirements.txt
```

### æ­¥éª¤ 2: ä»£ç æ›´æ–°

#### 2.1 æ›´æ–°å¯¼å…¥è¯­å¥
```bash
# ä½¿ç”¨è„šæœ¬æ‰¹é‡æ›¿æ¢å¯¼å…¥è¯­å¥
python scripts/update_imports.py
```

#### 2.2 æ›´æ–° Agent å®šä¹‰
- å°†æ‰€æœ‰ `initialize_agent` æ›¿æ¢ä¸º `create_agent`
- æ›´æ–°å·¥å…·å®šä¹‰æ–¹å¼
- ä¿®æ”¹ Agent è°ƒç”¨é€»è¾‘

#### 2.3 æ›´æ–°å›è°ƒå¤„ç†å™¨
- å°†å›è°ƒå¤„ç†å™¨è¿ç§»åˆ°ä¸­é—´ä»¶ç³»ç»Ÿ
- æ›´æ–°ä½¿ç”¨ç»Ÿè®¡ç›¸å…³ä»£ç 

### æ­¥éª¤ 3: é…ç½®æ›´æ–°

#### 3.1 æ›´æ–° config.yaml
```yaml
# æ–°å¢ LangChain 1.0 ç›¸å…³é…ç½®
langchain:
  version: "1.0.3"
  enable_tracing: true
  
# æ›´æ–°æ¨¡å‹é…ç½®
models:
  default_model: "gpt-4o"
  temperature: 0.7
```

### æ­¥éª¤ 4: æµ‹è¯•éªŒè¯

#### 4.1 å•å…ƒæµ‹è¯•
```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
python -m pytest tests/

# è¿è¡Œç‰¹å®šæ¨¡å—æµ‹è¯•
python -m pytest tests/test_agents.py
python -m pytest tests/test_tools.py
```

#### 4.2 é›†æˆæµ‹è¯•
```bash
# å¯åŠ¨æœåŠ¡
cd src/backend
uvicorn agentchat.main:app --port 7860

# æµ‹è¯• API æ¥å£
curl -X POST "http://localhost:7860/api/v1/chat" \
  -H "Content-Type: application/json" \
  -d '{"dialog_id": "test", "user_input": "Hello"}'
```

---

## ğŸ› å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### é—®é¢˜ 1: å¯¼å…¥é”™è¯¯

**é”™è¯¯ä¿¡æ¯:**
```
ImportError: cannot import name 'initialize_agent' from 'langchain.agents'
```

**è§£å†³æ–¹æ¡ˆ:**
```python
# æ›¿æ¢æ—§çš„å¯¼å…¥
# from langchain.agents import initialize_agent

# ä½¿ç”¨æ–°çš„å¯¼å…¥
from langchain.agents import create_agent
```

### é—®é¢˜ 2: å·¥å…·å®šä¹‰é”™è¯¯

**é”™è¯¯ä¿¡æ¯:**
```
TypeError: Tool() missing required argument: 'args_schema'
```

**è§£å†³æ–¹æ¡ˆ:**
```python
from langchain_core.tools import tool
from typing import Annotated

@tool
def my_tool(query: Annotated[str, "Input query"]) -> str:
    """Tool description"""
    return f"Result for {query}"
```

### é—®é¢˜ 3: Agent è°ƒç”¨æ–¹å¼é”™è¯¯

**é”™è¯¯ä¿¡æ¯:**
```
AttributeError: 'CompiledGraph' object has no attribute 'run'
```

**è§£å†³æ–¹æ¡ˆ:**
```python
# æ—§çš„è°ƒç”¨æ–¹å¼
# result = agent.run("Hello")

# æ–°çš„è°ƒç”¨æ–¹å¼
result = agent.invoke({
    "messages": [{"role": "user", "content": "Hello"}]
})
```


## ğŸ“š å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£
- [LangChain 1.0 Agents æ–‡æ¡£](https://docs.langchain.com/oss/python/langchain/agents)
- [LangChain 1.0 è¿ç§»æŒ‡å—](https://python.langchain.com/docs/versions/migrating_to_langchain_1_0)
- [LangChain å·¥å…·æ–‡æ¡£](https://docs.langchain.com/oss/python/langchain/tools)
- [LangChain ä¸­é—´ä»¶æ–‡æ¡£](https://docs.langchain.com/oss/python/langchain/middleware)

### ç¤¾åŒºèµ„æº
- [LangChain GitHub Issues](https://github.com/langchain-ai/langchain/issues)
- [LangChain Discord ç¤¾åŒº](https://discord.gg/langchain)

### AgentChat ç›¸å…³
- [AgentChat æŠ€æœ¯æ–‡æ¡£](./agentchat.md)
- [API æ–‡æ¡£](./api.md)
- [æ ¸å¿ƒåŠŸèƒ½æ–‡æ¡£](./core.md)

---

## ğŸ†˜ è·å–å¸®åŠ©

å¦‚æœåœ¨è¿ç§»è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è·å–å¸®åŠ©ï¼š

1. **æŸ¥çœ‹æ—¥å¿—**: æ£€æŸ¥åº”ç”¨æ—¥å¿—ä¸­çš„é”™è¯¯ä¿¡æ¯
2. **è¿è¡Œæµ‹è¯•**: ä½¿ç”¨æµ‹è¯•å¥—ä»¶éªŒè¯åŠŸèƒ½
3. **æäº¤ Issue**: åœ¨ GitHub ä»“åº“ä¸­æäº¤é—®é¢˜
4. **ç¤¾åŒºè®¨è®º**: å‚ä¸ç¤¾åŒºè®¨è®ºè·å–å¸®åŠ©

---

## âœ… è¿ç§»æ£€æŸ¥æ¸…å•

- [ ] å¤‡ä»½æ•°æ®å’Œé…ç½®æ–‡ä»¶
- [ ] æ›´æ–° Python ç‰ˆæœ¬åˆ° 3.12+
- [ ] å®‰è£…æ–°ç‰ˆæœ¬ä¾èµ–åŒ…
- [ ] è¿è¡Œå¯¼å…¥æ›´æ–°è„šæœ¬
- [ ] è¿è¡Œ Pydantic å…¼å®¹æ€§ä¿®å¤è„šæœ¬
- [ ] å°† `initialize_agent` æ›¿æ¢ä¸º `create_agent`
- [ ] æ›´æ–°å·¥å…·å®šä¹‰ä¸º `@tool` è£…é¥°å™¨
- [ ] å°†å›è°ƒå¤„ç†å™¨è¿ç§»åˆ°ä¸­é—´ä»¶
- [ ] æ›´æ–° Agent è°ƒç”¨æ–¹å¼ (`run` â†’ `invoke`)
- [ ] è¿è¡Œå•å…ƒæµ‹è¯•
- [ ] è¿è¡Œé›†æˆæµ‹è¯•
- [ ] éªŒè¯ API æ¥å£åŠŸèƒ½
- [ ] éªŒè¯å‰ç«¯ç•Œé¢åŠŸèƒ½
- [ ] éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ

---

*æœ€åæ›´æ–°æ—¶é—´: 2025å¹´10æœˆ*
*åŸºäº LangChain 1.0 å®˜æ–¹æ–‡æ¡£ç¼–å†™*